<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [æ¶ˆè´¹è€…äº‹ä»¶æ¶ˆè´¹](#%E6%B6%88%E8%B4%B9%E8%80%85%E4%BA%8B%E4%BB%B6%E6%B6%88%E8%B4%B9)
  - [é¡¹ç›®ä½œç”¨](#%E9%A1%B9%E7%9B%AE%E4%BD%9C%E7%94%A8)
  - [é¡¹ç›®ç»“æ„](#%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84)
  - [æ ¸å¿ƒå®ç°](#%E6%A0%B8%E5%BF%83%E5%AE%9E%E7%8E%B0)
    - [1. ä¾èµ–é…ç½®](#1-%E4%BE%9D%E8%B5%96%E9%85%8D%E7%BD%AE)
    - [2. é…ç½®æ–‡ä»¶](#2-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6)
    - [3. Kafkaæ¶ˆè´¹è€…é…ç½®ç±»](#3-kafka%E6%B6%88%E8%B4%B9%E8%80%85%E9%85%8D%E7%BD%AE%E7%B1%BB)
    - [4. ç®€å•æ¶ˆè´¹è€…](#4-%E7%AE%80%E5%8D%95%E6%B6%88%E8%B4%B9%E8%80%85)
    - [5. æ‰¹é‡æ¶ˆè´¹è€…](#5-%E6%89%B9%E9%87%8F%E6%B6%88%E8%B4%B9%E8%80%85)
    - [6. æ‰‹åŠ¨æäº¤æ¶ˆè´¹è€…](#6-%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4%E6%B6%88%E8%B4%B9%E8%80%85)
  - [Kafka Consumeræ¶ˆè´¹æ¨¡å¼è¯¦è§£](#kafka-consumer%E6%B6%88%E8%B4%B9%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3)
    - [1. æ¶ˆè´¹è€…ç±»å‹è¯´æ˜](#1-%E6%B6%88%E8%B4%B9%E8%80%85%E7%B1%BB%E5%9E%8B%E8%AF%B4%E6%98%8E)
    - [2. æ¶ˆè´¹æ¨¡å¼å¯¹æ¯”](#2-%E6%B6%88%E8%B4%B9%E6%A8%A1%E5%BC%8F%E5%AF%B9%E6%AF%94)
    - [3. æ¶ˆè´¹è€…é…ç½®è¯´æ˜](#3-%E6%B6%88%E8%B4%B9%E8%80%85%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E)
      - [è‡ªåŠ¨æäº¤æ¨¡å¼é…ç½®](#%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4%E6%A8%A1%E5%BC%8F%E9%85%8D%E7%BD%AE)
      - [æ‰‹åŠ¨æäº¤æ¨¡å¼é…ç½®](#%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4%E6%A8%A1%E5%BC%8F%E9%85%8D%E7%BD%AE)
    - [4. æ¶ˆè´¹è€…ç»„è¯´æ˜](#4-%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E8%AF%B4%E6%98%8E)
  - [æµ‹è¯•æ–¹æ³•](#%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95)
    - [1. å¯åŠ¨åº”ç”¨](#1-%E5%90%AF%E5%8A%A8%E5%BA%94%E7%94%A8)
    - [2. å‘é€æµ‹è¯•æ¶ˆæ¯](#2-%E5%8F%91%E9%80%81%E6%B5%8B%E8%AF%95%E6%B6%88%E6%81%AF)
      - [2.1 ç®€å•æ¶ˆè´¹è€…æµ‹è¯•](#21-%E7%AE%80%E5%8D%95%E6%B6%88%E8%B4%B9%E8%80%85%E6%B5%8B%E8%AF%95)
      - [2.2 æ‰¹é‡æ¶ˆè´¹è€…æµ‹è¯•](#22-%E6%89%B9%E9%87%8F%E6%B6%88%E8%B4%B9%E8%80%85%E6%B5%8B%E8%AF%95)
      - [2.3 æ‰‹åŠ¨æäº¤æ¶ˆè´¹è€…æµ‹è¯•](#23-%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4%E6%B6%88%E8%B4%B9%E8%80%85%E6%B5%8B%E8%AF%95)
      - [2.4 é€šç”¨æµ‹è¯•å‘½ä»¤](#24-%E9%80%9A%E7%94%A8%E6%B5%8B%E8%AF%95%E5%91%BD%E4%BB%A4)
    - [3. è§‚å¯Ÿæ—¥å¿—è¾“å‡º](#3-%E8%A7%82%E5%AF%9F%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA)
      - [ç®€å•æ¶ˆè´¹è€…æ—¥å¿—](#%E7%AE%80%E5%8D%95%E6%B6%88%E8%B4%B9%E8%80%85%E6%97%A5%E5%BF%97)
      - [æ‰¹é‡æ¶ˆè´¹è€…æ—¥å¿—](#%E6%89%B9%E9%87%8F%E6%B6%88%E8%B4%B9%E8%80%85%E6%97%A5%E5%BF%97)
      - [æ‰‹åŠ¨æäº¤æ¶ˆè´¹è€…æ—¥å¿—](#%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4%E6%B6%88%E8%B4%B9%E8%80%85%E6%97%A5%E5%BF%97)
  - [æµ‹è¯•å‘½ä»¤å¿«é€Ÿå‚è€ƒ](#%E6%B5%8B%E8%AF%95%E5%91%BD%E4%BB%A4%E5%BF%AB%E9%80%9F%E5%8F%82%E8%80%83)
    - [æ¶ˆè´¹è€…ç±»å‹ä¸æµ‹è¯•å‘½ä»¤å¯¹åº”å…³ç³»](#%E6%B6%88%E8%B4%B9%E8%80%85%E7%B1%BB%E5%9E%8B%E4%B8%8E%E6%B5%8B%E8%AF%95%E5%91%BD%E4%BB%A4%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB)
    - [ç‰¹æ®Šæµ‹è¯•åœºæ™¯](#%E7%89%B9%E6%AE%8A%E6%B5%8B%E8%AF%95%E5%9C%BA%E6%99%AF)
  - [æ³¨æ„äº‹é¡¹](#%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# æ¶ˆè´¹è€…äº‹ä»¶æ¶ˆè´¹

## é¡¹ç›®ä½œç”¨

æœ¬é¡¹ç›®æ¼”ç¤ºäº†SpringBootä¸­Kafka Consumerçš„å¤šç§æ¶ˆè´¹æ¨¡å¼å®ç°å’Œä½¿ç”¨ï¼ŒåŒ…æ‹¬ç®€å•æ¶ˆè´¹è€…ã€æ‰¹é‡æ¶ˆè´¹è€…ã€æ‰‹åŠ¨æäº¤æ¶ˆè´¹è€…ç­‰ä¸åŒç±»å‹ï¼Œå¸®åŠ©å¼€å‘è€…ç†è§£Kafkaæ¶ˆè´¹è€…çš„å·¥ä½œåŸç†å’Œå®é™…åº”ç”¨åœºæ™¯ã€‚

## é¡¹ç›®ç»“æ„

```
kafka-08-Event-Consumer/
â”œâ”€â”€ src/main/java/com/action/kafka08eventconsumer/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ KafkaConsumerConfig.java              # Kafkaæ¶ˆè´¹è€…é…ç½®ç±»
â”‚   â”œâ”€â”€ consumer/
â”‚   â”‚   â”œâ”€â”€ SimpleConsumer.java                   # ç®€å•æ¶ˆè´¹è€…
â”‚   â”‚   â”œâ”€â”€ BatchConsumer.java                    # æ‰¹é‡æ¶ˆè´¹è€…
â”‚   â”‚   â””â”€â”€ ManualCommitConsumer.java             # æ‰‹åŠ¨æäº¤æ¶ˆè´¹è€…
â”‚   â””â”€â”€ Kafka08EventConsumerApplication.java      # ä¸»å¯åŠ¨ç±»
â”œâ”€â”€ src/main/resources/
â”‚   â””â”€â”€ application.properties                    # é…ç½®æ–‡ä»¶
â””â”€â”€ pom.xml                                       # Mavené…ç½®
```

## æ ¸å¿ƒå®ç°

### 1. ä¾èµ–é…ç½®

`pom.xml`ï¼šå¼•å…¥Kafkaç›¸å…³ä¾èµ–

```xml

<dependencies>
    <!-- Spring Boot Starter -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter</artifactId>
    </dependency>

    <!-- Spring Kafka -->
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka</artifactId>
    </dependency>

    <!-- Lombok -->
    <dependency>
        <groupId>org.projectlombok</groupId>
        <artifactId>lombok</artifactId>
    </dependency>
</dependencies>
```

### 2. é…ç½®æ–‡ä»¶

`application.properties`ï¼šKafkaæœåŠ¡å™¨å’Œæ¶ˆè´¹è€…é…ç½®

```properties
# ========================================
# Kafka äº‹ä»¶æ¶ˆè´¹è€…æ¼”ç¤ºåº”ç”¨é…ç½®
# ========================================
# åº”ç”¨åç§°
spring.application.name=kafka-08-Event-Consumer
# ========================================
# Kafka è¿æ¥é…ç½®
# ========================================
# Kafka æœåŠ¡å™¨åœ°å€ï¼ˆå¤šä¸ªåœ°å€ç”¨é€—å·åˆ†éš”ï¼‰
# é»˜è®¤ï¼š192.168.56.10:9092
spring.kafka.bootstrap-servers=192.168.56.10:9092
# ========================================
# æ¼”ç¤º Topic é…ç½®
# ========================================
# æ¼”ç¤ºç”¨çš„ Topic åç§°
# åº”ç”¨å¯åŠ¨æ—¶ä¼šè‡ªåŠ¨åˆ›å»ºè¯¥ Topicï¼ˆ3ä¸ªåˆ†åŒºï¼Œ1ä¸ªå‰¯æœ¬ï¼‰
demo.topic.name=demo-consumer-topic
# ========================================
# æ¶ˆè´¹è€…é…ç½®
# ========================================
# æ¶ˆè´¹è€…ç»„IDï¼šç”¨äºæ ‡è¯†æ¶ˆè´¹è€…ç»„
spring.kafka.consumer.group-id=demo-consumer-group
# é”®ååºåˆ—åŒ–å™¨ï¼šå°†å­—èŠ‚æ•°ç»„ååºåˆ—åŒ–ä¸ºå­—ç¬¦ä¸²
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# å€¼ååºåˆ—åŒ–å™¨ï¼šå°†å­—èŠ‚æ•°ç»„ååºåˆ—åŒ–ä¸ºå­—ç¬¦ä¸²
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# è‡ªåŠ¨æäº¤åç§»é‡ï¼štrueè¡¨ç¤ºè‡ªåŠ¨æäº¤ï¼Œfalseè¡¨ç¤ºæ‰‹åŠ¨æäº¤
spring.kafka.consumer.enable-auto-commit=true
# è‡ªåŠ¨æäº¤é—´éš”ï¼šè‡ªåŠ¨æäº¤æ¨¡å¼ä¸‹çš„æäº¤é—´éš”ï¼ˆæ¯«ç§’ï¼‰
spring.kafka.consumer.auto-commit-interval=1000
# åç§»é‡é‡ç½®ç­–ç•¥ï¼šearliestï¼ˆä»æœ€æ—©å¼€å§‹ï¼‰ã€latestï¼ˆä»æœ€æ–°å¼€å§‹ï¼‰ã€noneï¼ˆæ— åç§»é‡æ—¶æŠ›å‡ºå¼‚å¸¸ï¼‰
spring.kafka.consumer.auto-offset-reset=earliest
# ä¼šè¯è¶…æ—¶æ—¶é—´ï¼šæ¶ˆè´¹è€…ä¸åè°ƒå™¨å¤±å»è¿æ¥çš„è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
spring.kafka.consumer.session-timeout=30000
# å¿ƒè·³é—´éš”ï¼šæ¶ˆè´¹è€…å‘é€å¿ƒè·³çš„é—´éš”æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
spring.kafka.consumer.heartbeat-interval=3000
# æœ€å¤§æ‹‰å–è®°å½•æ•°ï¼šå•æ¬¡æ‹‰å–çš„æœ€å¤§è®°å½•æ•°
spring.kafka.consumer.max-poll-records=500
# æ‹‰å–è¶…æ—¶æ—¶é—´ï¼šæ‹‰å–æ•°æ®çš„è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
spring.kafka.consumer.fetch-max-wait=500
# ========================================
# ç›‘å¬å™¨é…ç½®
# ========================================
# ç›‘å¬å™¨ç¡®è®¤æ¨¡å¼ï¼šbatchï¼ˆæ‰¹é‡ç¡®è®¤ï¼‰ã€manualï¼ˆæ‰‹åŠ¨ç¡®è®¤ï¼‰ã€manual_immediateï¼ˆç«‹å³æ‰‹åŠ¨ç¡®è®¤ï¼‰
spring.kafka.listener.ack-mode=batch
# å¹¶å‘æ¶ˆè´¹è€…æ•°é‡ï¼šæ¯ä¸ªç›‘å¬å™¨å®¹å™¨çš„å¹¶å‘æ¶ˆè´¹è€…æ•°é‡
spring.kafka.listener.concurrency=1
# ç›‘å¬å™¨å®¹å™¨ç±»å‹ï¼šsingleï¼ˆå•çº¿ç¨‹ï¼‰ã€batchï¼ˆæ‰¹å¤„ç†ï¼‰
spring.kafka.listener.type=single
```

### 3. Kafkaæ¶ˆè´¹è€…é…ç½®ç±»

`config/KafkaConsumerConfig.java`ï¼šé…ç½®å¤šç§æ¶ˆè´¹è€…æ¨¡å¼å’Œç›‘å¬å™¨å®¹å™¨å·¥å‚

```java
package com.action.kafka08eventconsumer.config;

import org.apache.kafka.clients.admin.NewTopic;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.annotation.EnableKafka;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.config.TopicBuilder;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
import org.springframework.kafka.listener.ContainerProperties;

import java.util.HashMap;
import java.util.Map;

/**
 * Kafka æ¶ˆè´¹è€…é…ç½®ç±»
 *
 * åŠŸèƒ½è¯´æ˜ï¼š
 * 1) é…ç½®æ¶ˆè´¹è€…åŸºæœ¬å‚æ•°ï¼šååºåˆ—åŒ–å™¨ã€æœåŠ¡å™¨åœ°å€ã€æ¶ˆè´¹è€…ç»„ç­‰
 * 2) é…ç½®å¤šç§ç›‘å¬å™¨å®¹å™¨å·¥å‚ï¼šæ”¯æŒä¸åŒçš„æ¶ˆè´¹æ¨¡å¼
 * 3) åˆ›å»ºæ¼”ç¤ºç”¨çš„ Topic
 * 4) æ”¯æŒè‡ªåŠ¨æäº¤å’Œæ‰‹åŠ¨æäº¤ä¸¤ç§æ¨¡å¼
 */
@Configuration
@EnableKafka
public class KafkaConsumerConfig {

    @Value("${spring.kafka.bootstrap-servers:192.168.56.10:9092}")
    private String bootstrapServers;

    @Value("${spring.kafka.consumer.group-id:demo-consumer-group}")
    private String groupId;

    @Value("${demo.topic.name:demo-consumer-topic}")
    private String demoTopic;

    /**
     * æ¶ˆè´¹è€…é…ç½®å‚æ•°ï¼ˆè‡ªåŠ¨æäº¤æ¨¡å¼ï¼‰
     */
    @Bean
    public Map<String, Object> consumerConfigs() {
        Map<String, Object> props = new HashMap<>();

        // åŸºæœ¬è¿æ¥é…ç½®
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);

        // æ¶ˆè´¹è€…ç»„é…ç½®
        props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);

        // åç§»é‡é…ç½®
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);
        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 1000);

        // æ€§èƒ½é…ç½®
        props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 30000);
        props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 3000);
        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500);
        props.put(ConsumerConfig.FETCH_MAX_WAIT_MS_CONFIG, 500);

        return props;
    }

    /**
     * æ¶ˆè´¹è€…é…ç½®å‚æ•°ï¼ˆæ‰‹åŠ¨æäº¤æ¨¡å¼ï¼‰
     */
    @Bean
    public Map<String, Object> manualCommitConsumerConfigs() {
        Map<String, Object> props = new HashMap<>();

        // åŸºæœ¬è¿æ¥é…ç½®
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);

        // æ¶ˆè´¹è€…ç»„é…ç½®
        props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId + "-manual");

        // åç§»é‡é…ç½®ï¼ˆæ‰‹åŠ¨æäº¤ï¼‰
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);

        // æ€§èƒ½é…ç½®
        props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 30000);
        props.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 3000);
        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 100);
        props.put(ConsumerConfig.FETCH_MAX_WAIT_MS_CONFIG, 500);

        return props;
    }

    /**
     * æ¶ˆè´¹è€…å·¥å‚ï¼ˆè‡ªåŠ¨æäº¤æ¨¡å¼ï¼‰
     */
    @Bean
    public ConsumerFactory<String, String> consumerFactory() {
        return new DefaultKafkaConsumerFactory<>(consumerConfigs());
    }

    /**
     * æ¶ˆè´¹è€…å·¥å‚ï¼ˆæ‰‹åŠ¨æäº¤æ¨¡å¼ï¼‰
     */
    @Bean
    public ConsumerFactory<String, String> manualCommitConsumerFactory() {
        return new DefaultKafkaConsumerFactory<>(manualCommitConsumerConfigs());
    }

    /**
     * ç›‘å¬å™¨å®¹å™¨å·¥å‚ï¼ˆè‡ªåŠ¨æäº¤æ¨¡å¼ï¼‰
     */
    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, String> factory =
                new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.BATCH);
        factory.setConcurrency(1);
        return factory;
    }

    /**
     * ç›‘å¬å™¨å®¹å™¨å·¥å‚ï¼ˆæ‰‹åŠ¨æäº¤æ¨¡å¼ï¼‰
     */
    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> manualCommitKafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, String> factory =
                new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(manualCommitConsumerFactory());
        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL);
        factory.setConcurrency(1);
        return factory;
    }

    /**
     * ç›‘å¬å™¨å®¹å™¨å·¥å‚ï¼ˆæ‰¹é‡æ¶ˆè´¹æ¨¡å¼ï¼‰
     */
    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> batchKafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, String> factory =
                new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        factory.setBatchListener(true);
        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.BATCH);
        factory.setConcurrency(1);
        return factory;
    }

    /**
     * æ¼”ç¤ºç”¨ Topic Bean
     */
    @Bean
    public NewTopic demoTopic() {
        return TopicBuilder.name(demoTopic)
                .partitions(3)
                .replicas(1)
                .build();
    }
}
```

### 4. ç®€å•æ¶ˆè´¹è€…

`consumer/SimpleConsumer.java`ï¼šæ¼”ç¤ºåŸºæœ¬çš„æ¶ˆæ¯æ¶ˆè´¹åŠŸèƒ½

```java
package com.action.kafka08eventconsumer.consumer;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.support.KafkaHeaders;
import org.springframework.messaging.handler.annotation.Header;
import org.springframework.messaging.handler.annotation.Payload;
import org.springframework.stereotype.Component;

/**
 * ç®€å•æ¶ˆè´¹è€… - æ¼”ç¤ºåŸºæœ¬çš„æ¶ˆæ¯æ¶ˆè´¹åŠŸèƒ½
 *
 * åŠŸèƒ½è¯´æ˜ï¼š
 * 1) è‡ªåŠ¨æäº¤æ¨¡å¼ï¼šæ¶ˆè´¹æ¶ˆæ¯åè‡ªåŠ¨æäº¤åç§»é‡
 * 2) å•æ¡æ¶ˆè´¹ï¼šä¸€æ¬¡å¤„ç†ä¸€æ¡æ¶ˆæ¯
 * 3) æ—¥å¿—è®°å½•ï¼šè®°å½•æ¶ˆè´¹çš„æ¶ˆæ¯è¯¦æƒ…
 * 4) å¼‚å¸¸å¤„ç†ï¼šæ•è·å¹¶è®°å½•æ¶ˆè´¹å¼‚å¸¸
 */
@Component
public class SimpleConsumer {

    private static final Logger log = LoggerFactory.getLogger(SimpleConsumer.class);

    /**
     * ç®€å•æ¶ˆæ¯æ¶ˆè´¹æ–¹æ³•ï¼ˆä½¿ç”¨ ConsumerRecordï¼‰
     *
     * æ‰§è¡Œæ—¶æœºï¼šå½“æœ‰æ¶ˆæ¯åˆ°è¾¾æŒ‡å®š topic æ—¶
     * ä½œç”¨ï¼šå¤„ç†å•æ¡æ¶ˆæ¯ï¼Œè®°å½•æ¶ˆè´¹è¯¦æƒ…
     *
     * å‚æ•°è¯´æ˜ï¼š
     * - topics: ç›‘å¬çš„ topic åç§°
     * - groupId: æ¶ˆè´¹è€…ç»„ID
     * - containerFactory: ä½¿ç”¨çš„ç›‘å¬å™¨å®¹å™¨å·¥å‚
     *
     * æµ‹è¯•å‘½ä»¤ï¼š
     * # å‘é€å•æ¡æ¶ˆæ¯ï¼ˆæ— é”®ï¼‰
     * kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     *
     * # å‘é€å•æ¡æ¶ˆæ¯ï¼ˆå¸¦é”®ï¼‰
     * kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"
     *
     * # å‘é€æµ‹è¯•æ¶ˆæ¯ç¤ºä¾‹
     * echo "Hello Kafka Consumer" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     * echo "key1:test message 1" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"
     *
     * @param record æ¶ˆæ¯è®°å½•å¯¹è±¡
     */
    @KafkaListener(
            topics = "${demo.topic.name:demo-consumer-topic}",
            groupId = "${spring.kafka.consumer.group-id:demo-consumer-group}",
            containerFactory = "kafkaListenerContainerFactory"
    )
    public void consumeMessage(ConsumerRecord<String, String> record) {
        try {
            // æ¶ˆè´¹ä¿¡æ¯æ—¥å¿—
            log.info("ğŸ“¦ Simple Consumer (ConsumerRecord) ğŸ‘¥ Group: {} ğŸ“‹ Topic: {} ğŸ”¢ Partition: {} ğŸ“ Offset: {} ğŸ”‘ Key: {} ğŸ’¬ Value: {} â° Timestamp: {} ğŸ“„ Headers: {}", 
                    groupId, record.topic(), record.partition(), record.offset(), record.key(), record.value(), record.timestamp(), record.headers());

            // æ¨¡æ‹Ÿæ¶ˆæ¯å¤„ç†é€»è¾‘
            processMessage(record.value());

        } catch (Exception ex) {
            log.error("Error processing message from topic={}, partition={}, offset={}",
                    record.topic(), record.partition(), record.offset(), ex);
        }
    }

    /**
     * ç®€å•æ¶ˆæ¯æ¶ˆè´¹æ–¹æ³•ï¼ˆä½¿ç”¨ @Payload å’Œ @Headerï¼‰
     *
     * æ‰§è¡Œæ—¶æœºï¼šå½“æœ‰æ¶ˆæ¯åˆ°è¾¾æŒ‡å®š topic æ—¶
     * ä½œç”¨ï¼šä½¿ç”¨æ³¨è§£æ–¹å¼ç®€åŒ–å‚æ•°å¤„ç†
     *
     * å‚æ•°è¯´æ˜ï¼š
     * - @Payload: ç›´æ¥è·å–æ¶ˆæ¯å€¼ï¼Œç±»å‹è‡ªåŠ¨è½¬æ¢
     * - @Header: è·å–æŒ‡å®šçš„æ¶ˆæ¯å¤´ä¿¡æ¯
     *
     * æµ‹è¯•å‘½ä»¤ï¼š
     * # å‘é€å•æ¡æ¶ˆæ¯ï¼ˆæ— é”®ï¼‰
     * kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     *
     * # å‘é€å•æ¡æ¶ˆæ¯ï¼ˆå¸¦é”®ï¼‰
     * kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"
     *
     * # å‘é€æµ‹è¯•æ¶ˆæ¯ç¤ºä¾‹
     * echo "Payload test message" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     * echo "payload-key:Payload test with key" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"
     *
     * @param message æ¶ˆæ¯å€¼
     * @param partition åˆ†åŒºå·
     * @param offset åç§»é‡
     * @param key æ¶ˆæ¯é”®
     */
    @KafkaListener(
            topics = "${demo.topic.name:demo-consumer-topic}",
            groupId = "${spring.kafka.consumer.group-id:demo-consumer-group}-payload",
            containerFactory = "kafkaListenerContainerFactory"
    )
    public void consumeMessageWithPayload(
            @Payload String message,
            @Header(KafkaHeaders.RECEIVED_PARTITION) int partition,
            @Header(KafkaHeaders.OFFSET) long offset,
            @Header(value = KafkaHeaders.RECEIVED_KEY, required = false) String key) {

        try {
            // æ¶ˆè´¹ä¿¡æ¯æ—¥å¿—
            log.info("ğŸ“¦ Simple Consumer (@Payload/@Header) ğŸ‘¥ Group: {} ğŸ”¢ Partition: {} ğŸ“ Offset: {} ğŸ”‘ Key: {} ğŸ’¬ Value: {} ğŸ”„ Acknowledgment: Auto", 
                    groupId + "-payload", partition, offset, key != null ? key : "null", message);

            processMessage(message);

        } catch (Exception ex) {
            log.error("Error processing message from partition={}, offset={}",
                    partition, offset, ex);
        }
    }

    /**
     * æ¶ˆæ¯å¤„ç†é€»è¾‘
     */
    private void processMessage(String message) {
        try {
            Thread.sleep(100);

            if (message.contains("error")) {
                log.warn("Processing error message: {}", message);
            } else if (message.contains("urgent")) {
                log.warn("Processing urgent message: {}", message);
            } else {
                log.info("Processing normal message: {}", message);
            }

        } catch (InterruptedException ex) {
            Thread.currentThread().interrupt();
            log.error("Message processing interrupted", ex);
        } catch (Exception ex) {
            log.error("Error in message processing", ex);
        }
    }
}
```

### 5. æ‰¹é‡æ¶ˆè´¹è€…

`consumer/BatchConsumer.java`ï¼šæ¼”ç¤ºæ‰¹é‡æ¶ˆæ¯æ¶ˆè´¹åŠŸèƒ½

```java
package com.action.kafka08eventconsumer.consumer;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.kafka.support.KafkaHeaders;
import org.springframework.messaging.handler.annotation.Header;
import org.springframework.messaging.handler.annotation.Payload;
import org.springframework.stereotype.Component;

import java.util.List;

/**
 * æ‰¹é‡æ¶ˆè´¹è€… - æ¼”ç¤ºæ‰¹é‡æ¶ˆæ¯æ¶ˆè´¹åŠŸèƒ½
 *
 * åŠŸèƒ½è¯´æ˜ï¼š
 * 1) æ‰¹é‡æ¶ˆè´¹ï¼šä¸€æ¬¡å¤„ç†å¤šæ¡æ¶ˆæ¯ï¼Œæé«˜æ¶ˆè´¹æ•ˆç‡
 * 2) è‡ªåŠ¨æäº¤æ¨¡å¼ï¼šæ¶ˆè´¹å®Œæˆåè‡ªåŠ¨æäº¤åç§»é‡
 * 3) æ‰¹é‡å¤„ç†ï¼šé€‚åˆé«˜ååé‡åœºæ™¯
 * 4) ç»Ÿè®¡ä¿¡æ¯ï¼šè®°å½•æ‰¹é‡æ¶ˆè´¹çš„ç»Ÿè®¡ä¿¡æ¯
 */
@Component
public class BatchConsumer {

    private static final Logger log = LoggerFactory.getLogger(BatchConsumer.class);

    // æ‰¹é‡æ¶ˆè´¹ç»Ÿè®¡ä¿¡æ¯
    private long totalBatches = 0;
    private long totalMessages = 0;

    /**
     * æ‰¹é‡æ¶ˆæ¯æ¶ˆè´¹æ–¹æ³•ï¼ˆä½¿ç”¨ List<ConsumerRecord>ï¼‰
     *
     * æ‰§è¡Œæ—¶æœºï¼šå½“æœ‰æ¶ˆæ¯æ‰¹æ¬¡åˆ°è¾¾æŒ‡å®š topic æ—¶
     * ä½œç”¨ï¼šæ‰¹é‡å¤„ç†æ¶ˆæ¯ï¼Œæé«˜æ¶ˆè´¹æ•ˆç‡
     *
     * å‚æ•°è¯´æ˜ï¼š
     * - topics: ç›‘å¬çš„ topic åç§°
     * - groupId: æ¶ˆè´¹è€…ç»„ID
     * - containerFactory: ä½¿ç”¨æ‰¹é‡æ¶ˆè´¹çš„ç›‘å¬å™¨å®¹å™¨å·¥å‚
     *
     * æµ‹è¯•å‘½ä»¤ï¼š
     * # å‘é€æ‰¹é‡æ¶ˆæ¯ï¼ˆæ— é”®ï¼‰
     * for i in {1..5}; do echo "batch message $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; done
     *
     * # å‘é€æ‰¹é‡æ¶ˆæ¯ï¼ˆå¸¦é”®ï¼‰
     * for i in {1..3}; do echo "batch-key-$i:batch message with key $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"; done
     *
     * # å¿«é€Ÿå‘é€å¤šæ¡æ¶ˆæ¯æµ‹è¯•æ‰¹é‡æ¶ˆè´¹
     * for i in {1..10}; do echo "rapid message $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; sleep 0.1; done
     *
     * @param records æ‰¹é‡æ¶ˆæ¯è®°å½•åˆ—è¡¨
     */
    @KafkaListener(
            topics = "${demo.topic.name:demo-consumer-topic}",
            groupId = "${spring.kafka.consumer.group-id:demo-consumer-group}-batch",
            containerFactory = "batchKafkaListenerContainerFactory"
    )
    public void consumeBatchMessages(List<ConsumerRecord<String, String>> records) {
        try {
            totalBatches++;
            totalMessages += records.size();

            // æ‰¹é‡æ¶ˆè´¹ä¿¡æ¯æ—¥å¿—
            log.info("ğŸ“¦ Batch Consumer (List<ConsumerRecord>) ğŸ‘¥ Group: {} ğŸ“Š Batch size: {} ğŸ“ˆ Total batches: {} ğŸ“ˆ Total messages: {}", 
                    groupId + "-batch", records.size(), totalBatches, totalMessages);

            processBatchMessages(records);

            log.info("==========================================");

        } catch (Exception ex) {
            log.error("Error processing batch messages, batch size: {}", records.size(), ex);
        }
    }

    /**
     * æ‰¹é‡æ¶ˆæ¯æ¶ˆè´¹æ–¹æ³•ï¼ˆä½¿ç”¨ List<String>ï¼‰
     *
     * æ‰§è¡Œæ—¶æœºï¼šå½“æœ‰æ¶ˆæ¯æ‰¹æ¬¡åˆ°è¾¾æŒ‡å®š topic æ—¶
     * ä½œç”¨ï¼šä½¿ç”¨æ³¨è§£æ–¹å¼æ‰¹é‡å¤„ç†æ¶ˆæ¯
     *
     * å‚æ•°è¯´æ˜ï¼š
     * - @Payload: æ‰¹é‡æ¶ˆæ¯å€¼åˆ—è¡¨
     * - @Header: æ‰¹é‡æ¶ˆæ¯çš„å…¬å…±å¤´ä¿¡æ¯
     *
     * æµ‹è¯•å‘½ä»¤ï¼š
     * # å‘é€æ‰¹é‡æ¶ˆæ¯ï¼ˆæ— é”®ï¼‰
     * for i in {1..8}; do echo "payload batch message $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; done
     *
     * # å‘é€æ‰¹é‡æ¶ˆæ¯ï¼ˆå¸¦é”®ï¼‰
     * for i in {1..4}; do echo "payload-key-$i:payload batch with key $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"; done
     *
     * # æ··åˆå‘é€æµ‹è¯•ï¼ˆéƒ¨åˆ†æœ‰é”®ï¼Œéƒ¨åˆ†æ— é”®ï¼‰
     * echo "mixed message 1" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     * echo "mixed-key:mixed message with key" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"
     * echo "mixed message 3" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     *
     * @param messages æ‰¹é‡æ¶ˆæ¯å€¼åˆ—è¡¨
     * @param partitions åˆ†åŒºå·åˆ—è¡¨
     * @param offsets åç§»é‡åˆ—è¡¨
     * @param keys æ¶ˆæ¯é”®åˆ—è¡¨
     */
    @KafkaListener(
            topics = "${demo.topic.name:demo-consumer-topic}",
            groupId = "${spring.kafka.consumer.group-id:demo-consumer-group}-batch-payload",
            containerFactory = "manualBatchKafkaListenerContainerFactory"
    )
    public void consumeBatchMessagesWithPayload(
            @Payload List<String> messages,
            @Header(KafkaHeaders.RECEIVED_PARTITION_ID) List<Integer> partitions,
            @Header(KafkaHeaders.OFFSET) List<Long> offsets,
            @Header(value = KafkaHeaders.RECEIVED_KEY, required = false) List<String> keys) {

        try {
            totalBatches++;
            totalMessages += messages.size();

            // æ‰¹é‡æ¶ˆè´¹ä¿¡æ¯æ—¥å¿—
            log.info("ğŸ“¦ Batch Consumer (@Payload/@Header) ğŸ‘¥ Group: {} ğŸ“Š Batch size: {} ğŸ”¢ Partitions: {} ğŸ“ Offsets: {} ğŸ”‘ Keys: {} ğŸ“ˆ Total batches: {} ğŸ“ˆ Total messages: {}", 
                    groupId + "-batch-payload", messages.size(), partitions, offsets, keys, totalBatches, totalMessages);

            processBatchMessagesWithDetails(messages, partitions, offsets, keys);

            log.info("=========================================");

        } catch (Exception ex) {
            log.error("Error processing batch messages, batch size: {}", messages.size(), ex);
        }
    }

    /**
     * å¤„ç†æ‰¹é‡æ¶ˆæ¯ï¼ˆä½¿ç”¨ ConsumerRecordï¼‰
     */
    private void processBatchMessages(List<ConsumerRecord<String, String>> records) {
        try {
            records.stream()
                    .collect(java.util.stream.Collectors.groupingBy(ConsumerRecord::partition))
                    .forEach((partition, partitionRecords) -> {
                        log.info("Processing {} messages from partition {}",
                                partitionRecords.size(), partition);

                        partitionRecords.forEach(record -> {
                            log.debug("Message from partition {}: key={}, value={}, offset={}",
                                    record.partition(), record.key(), record.value(), record.offset());
                            processMessage(record.value());
                        });
                    });

            Thread.sleep(200);

        } catch (InterruptedException ex) {
            Thread.currentThread().interrupt();
            log.error("Batch processing interrupted", ex);
        } catch (Exception ex) {
            log.error("Error in batch processing", ex);
        }
    }

    /**
     * å¤„ç†æ‰¹é‡æ¶ˆæ¯ï¼ˆä½¿ç”¨è¯¦ç»†ä¿¡æ¯ï¼‰
     */
    private void processBatchMessagesWithDetails(List<String> messages,
                                                 List<Integer> partitions,
                                                 List<Long> offsets,
                                                 List<String> keys) {
        try {
            for (int i = 0; i < messages.size(); i++) {
                String message = messages.get(i);
                Integer partition = partitions.get(i);
                Long offset = offsets.get(i);
                String key = keys.get(i);

                log.debug("Message from partition {}: key={}, value={}, offset={}",
                        partition, key, message, offset);

                processMessage(message);
            }

            Thread.sleep(200);

        } catch (InterruptedException ex) {
            Thread.currentThread().interrupt();
            log.error("Batch processing interrupted", ex);
        } catch (Exception ex) {
            log.error("Error in batch processing", ex);
        }
    }

    /**
     * æ¶ˆæ¯å¤„ç†é€»è¾‘
     */
    private void processMessage(String message) {
        try {
            Thread.sleep(50);

            if (message.contains("error")) {
                log.warn("Processing error message: {}", message);
            } else if (message.contains("urgent")) {
                log.warn("Processing urgent message: {}", message);
            } else {
                log.debug("Processing normal message: {}", message);
            }

        } catch (InterruptedException ex) {
            Thread.currentThread().interrupt();
            log.error("Message processing interrupted", ex);
        } catch (Exception ex) {
            log.error("Error in message processing", ex);
        }
    }

    /**
     * è·å–æ‰¹é‡æ¶ˆè´¹ç»Ÿè®¡ä¿¡æ¯
     */
    public String getStatistics() {
        return String.format("Batch Consumer Statistics - Total Batches: %d, Total Messages: %d",
                totalBatches, totalMessages);
    }
}
```

### 6. æ‰‹åŠ¨æäº¤æ¶ˆè´¹è€…

`consumer/ManualCommitConsumer.java`ï¼šæ¼”ç¤ºæ‰‹åŠ¨æäº¤åç§»é‡çš„æ¶ˆæ¯æ¶ˆè´¹åŠŸèƒ½

```java
package com.action.kafka08eventconsumer.consumer;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.kafka.support.KafkaHeaders;
import org.springframework.messaging.handler.annotation.Header;
import org.springframework.messaging.handler.annotation.Payload;
import org.springframework.stereotype.Component;

import java.util.List;

/**
 * æ‰‹åŠ¨æäº¤æ¶ˆè´¹è€… - æ¼”ç¤ºæ‰‹åŠ¨æäº¤åç§»é‡çš„æ¶ˆæ¯æ¶ˆè´¹åŠŸèƒ½
 *
 * åŠŸèƒ½è¯´æ˜ï¼š
 * 1) æ‰‹åŠ¨æäº¤æ¨¡å¼ï¼šæ¶ˆè´¹æ¶ˆæ¯åéœ€è¦æ‰‹åŠ¨ç¡®è®¤åç§»é‡
 * 2) ç²¾ç¡®æ§åˆ¶ï¼šå¯ä»¥æ§åˆ¶ä½•æ—¶æäº¤åç§»é‡ï¼Œé¿å…æ¶ˆæ¯ä¸¢å¤±
 * 3) å¼‚å¸¸å¤„ç†ï¼šæ”¯æŒæ¶ˆè´¹å¤±è´¥æ—¶çš„é‡è¯•å’Œå›æ»šæœºåˆ¶
 * 4) æ‰¹é‡ç¡®è®¤ï¼šæ”¯æŒæ‰¹é‡å¤„ç†åçš„æ‰¹é‡ç¡®è®¤
 */
@Component
public class ManualCommitConsumer {

    private static final Logger log = LoggerFactory.getLogger(ManualCommitConsumer.class);

    // æ‰‹åŠ¨æäº¤ç»Ÿè®¡ä¿¡æ¯
    private long totalMessages = 0;
    private long successMessages = 0;
    private long failedMessages = 0;

    /**
     * æ‰‹åŠ¨æäº¤æ¶ˆæ¯æ¶ˆè´¹æ–¹æ³•ï¼ˆä½¿ç”¨ ConsumerRecordï¼‰
     *
     * æ‰§è¡Œæ—¶æœºï¼šå½“æœ‰æ¶ˆæ¯åˆ°è¾¾æŒ‡å®š topic æ—¶
     * ä½œç”¨ï¼šæ‰‹åŠ¨æ§åˆ¶åç§»é‡æäº¤ï¼Œç¡®ä¿æ¶ˆæ¯å¤„ç†å®Œæˆåå†æäº¤
     *
     * å‚æ•°è¯´æ˜ï¼š
     * - topics: ç›‘å¬çš„ topic åç§°
     * - groupId: æ¶ˆè´¹è€…ç»„ID
     * - containerFactory: ä½¿ç”¨æ‰‹åŠ¨æäº¤çš„ç›‘å¬å™¨å®¹å™¨å·¥å‚
     *
     * æµ‹è¯•å‘½ä»¤ï¼š
     * # å‘é€å•æ¡æ¶ˆæ¯ï¼ˆæ— é”®ï¼‰
     * kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     *
     * # å‘é€å•æ¡æ¶ˆæ¯ï¼ˆå¸¦é”®ï¼‰
     * kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"
     *
     * # å‘é€æµ‹è¯•æ¶ˆæ¯ç¤ºä¾‹
     * echo "Manual commit test message" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     * echo "manual-key:Manual commit with key" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"
     *
     * @param record æ¶ˆæ¯è®°å½•å¯¹è±¡
     * @param ack æ‰‹åŠ¨ç¡®è®¤æ¥å£
     */
    @KafkaListener(
            topics = "${demo.topic.name:demo-consumer-topic}",
            groupId = "${spring.kafka.consumer.group-id:demo-consumer-group}-manual",
            containerFactory = "manualCommitKafkaListenerContainerFactory"
    )
    public void consumeMessageWithManualCommit(ConsumerRecord<String, String> record, Acknowledgment ack) {
        try {
            totalMessages++;

            // æ‰‹åŠ¨æäº¤æ¶ˆè´¹ä¿¡æ¯æ—¥å¿—
            log.info("ğŸ“¦ Manual Commit Consumer (ConsumerRecord) ğŸ‘¥ Group: {} ğŸ“‹ Topic: {} ğŸ”¢ Partition: {} ğŸ“ Offset: {} ğŸ”‘ Key: {} ğŸ’¬ Value: {} â° Timestamp: {} ğŸ“Š Total: {} Success: {} Failed: {}", 
                    groupId + "-manual", record.topic(), record.partition(), record.offset(), record.key(), record.value(), record.timestamp(), totalMessages, successMessages, failedMessages);

            boolean success = processMessage(record.value());

            if (success) {
                ack.acknowledge();
                successMessages++;
                log.info("Message acknowledged successfully");
            } else {
                failedMessages++;
                log.warn("Message processing failed, will be retried");
            }

            log.info("=============================================");

        } catch (Exception ex) {
            failedMessages++;
            log.error("Error processing message from topic={}, partition={}, offset={}",
                    record.topic(), record.partition(), record.offset(), ex);
        }
    }

    /**
     * æ‰‹åŠ¨æäº¤æ¶ˆæ¯æ¶ˆè´¹æ–¹æ³•ï¼ˆä½¿ç”¨ @Payload å’Œ @Headerï¼‰
     *
     * æ‰§è¡Œæ—¶æœºï¼šå½“æœ‰æ¶ˆæ¯åˆ°è¾¾æŒ‡å®š topic æ—¶
     * ä½œç”¨ï¼šä½¿ç”¨æ³¨è§£æ–¹å¼ç®€åŒ–å‚æ•°å¤„ç†ï¼Œæ‰‹åŠ¨æ§åˆ¶åç§»é‡æäº¤
     *
     * å‚æ•°è¯´æ˜ï¼š
     * - @Payload: ç›´æ¥è·å–æ¶ˆæ¯å€¼ï¼Œç±»å‹è‡ªåŠ¨è½¬æ¢
     * - @Header: è·å–æŒ‡å®šçš„æ¶ˆæ¯å¤´ä¿¡æ¯
     * - Acknowledgment: æ‰‹åŠ¨ç¡®è®¤æ¥å£
     *
     * æµ‹è¯•å‘½ä»¤ï¼š
     * # å‘é€å•æ¡æ¶ˆæ¯ï¼ˆæ— é”®ï¼‰
     * kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     *
     * # å‘é€å•æ¡æ¶ˆæ¯ï¼ˆå¸¦é”®ï¼‰
     * kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"
     *
     * # å‘é€æµ‹è¯•æ¶ˆæ¯ç¤ºä¾‹
     * echo "Manual payload test message" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     * echo "manual-payload-key:Manual payload with key" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"
     *
     * @param message æ¶ˆæ¯å€¼
     * @param partition åˆ†åŒºå·
     * @param offset åç§»é‡
     * @param key æ¶ˆæ¯é”®
     * @param ack æ‰‹åŠ¨ç¡®è®¤æ¥å£
     */
    @KafkaListener(
            topics = "${demo.topic.name:demo-consumer-topic}",
            groupId = "${spring.kafka.consumer.group-id:demo-consumer-group}-manual-payload",
            containerFactory = "manualCommitKafkaListenerContainerFactory"
    )
    public void consumeMessageWithManualCommitPayload(
            @Payload String message,
            @Header(KafkaHeaders.RECEIVED_PARTITION) int partition,
            @Header(KafkaHeaders.OFFSET) long offset,
            @Header(value = KafkaHeaders.RECEIVED_KEY, required = false) String key,
            Acknowledgment ack) {

        try {
            totalMessages++;

            // æ‰‹åŠ¨æäº¤æ¶ˆè´¹ä¿¡æ¯æ—¥å¿—
            log.info("ğŸ“¦ Manual Commit Consumer (@Payload/@Header) ğŸ‘¥ Group: {} ğŸ”¢ Partition: {} ğŸ“ Offset: {} ğŸ”‘ Key: {} ğŸ’¬ Value: {} ğŸ“Š Total: {} Success: {} Failed: {}", 
                    groupId + "-manual-payload", partition, offset, key, message, totalMessages, successMessages, failedMessages);

            boolean success = processMessage(message);

            if (success) {
                ack.acknowledge();
                successMessages++;
                log.info("Message acknowledged successfully");
            } else {
                failedMessages++;
                log.warn("Message processing failed, will be retried");
            }

            log.info("===============================================");

        } catch (Exception ex) {
            failedMessages++;
            log.error("Error processing message from partition={}, offset={}",
                    partition, offset, ex);
        }
    }

    /**
     * æ‰‹åŠ¨æäº¤æ‰¹é‡æ¶ˆæ¯æ¶ˆè´¹æ–¹æ³•
     *
     * æ‰§è¡Œæ—¶æœºï¼šå½“æœ‰æ¶ˆæ¯æ‰¹æ¬¡åˆ°è¾¾æŒ‡å®š topic æ—¶
     * ä½œç”¨ï¼šæ‰¹é‡å¤„ç†æ¶ˆæ¯ï¼Œæ‰‹åŠ¨æ§åˆ¶åç§»é‡æäº¤
     *
     * å‚æ•°è¯´æ˜ï¼š
     * - @Payload: æ‰¹é‡æ¶ˆæ¯å€¼åˆ—è¡¨
     * - @Header: æ‰¹é‡æ¶ˆæ¯çš„å…¬å…±å¤´ä¿¡æ¯
     * - Acknowledgment: æ‰‹åŠ¨ç¡®è®¤æ¥å£
     *
     * æµ‹è¯•å‘½ä»¤ï¼š
     * # å‘é€æ‰¹é‡æ¶ˆæ¯ï¼ˆæ— é”®ï¼‰
     * for i in {1..6}; do echo "manual batch message $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; done
     *
     * # å‘é€æ‰¹é‡æ¶ˆæ¯ï¼ˆå¸¦é”®ï¼‰
     * for i in {1..4}; do echo "manual-batch-key-$i:manual batch with key $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"; done
     *
     * # å¿«é€Ÿå‘é€å¤šæ¡æ¶ˆæ¯æµ‹è¯•æ‰¹é‡æ‰‹åŠ¨æäº¤
     * for i in {1..15}; do echo "rapid manual batch $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; sleep 0.05; done
     *
     * # å‘é€åŒ…å«é”™è¯¯æ¶ˆæ¯çš„æ‰¹æ¬¡æµ‹è¯•
     * echo "error message" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     * echo "normal message" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     *
     * @param messages æ‰¹é‡æ¶ˆæ¯å€¼åˆ—è¡¨
     * @param partitions åˆ†åŒºå·åˆ—è¡¨
     * @param offsets åç§»é‡åˆ—è¡¨
     * @param keys æ¶ˆæ¯é”®åˆ—è¡¨
     * @param ack æ‰‹åŠ¨ç¡®è®¤æ¥å£
     */
    @KafkaListener(
            topics = "${demo.topic.name:demo-consumer-topic}",
            groupId = "${spring.kafka.consumer.group-id:demo-consumer-group}-manual-batch",
            containerFactory = "manualCommitKafkaListenerContainerFactory"
    )
    public void consumeBatchMessagesWithManualCommit(
            @Payload List<String> messages,
            @Header(KafkaHeaders.RECEIVED_PARTITION_ID) List<Integer> partitions,
            @Header(KafkaHeaders.OFFSET) List<Long> offsets,
            @Header(value = KafkaHeaders.RECEIVED_KEY, required = false) List<String> keys,
            Acknowledgment ack) {

        try {
            totalMessages += messages.size();

            // æ‰¹é‡æ‰‹åŠ¨æäº¤æ¶ˆè´¹ä¿¡æ¯æ—¥å¿—
            log.info("ğŸ“¦ Manual Commit Batch Consumer ğŸ‘¥ Group: {} ğŸ“Š Batch size: {} ğŸ”¢ Partitions: {} ğŸ“ Offsets: {} ğŸ”‘ Keys: {} ğŸ“Š Total: {} Success: {} Failed: {}", 
                    groupId + "-manual-batch", messages.size(), partitions, offsets, keys, totalMessages, successMessages, failedMessages);

            boolean allSuccess = processBatchMessages(messages, partitions, offsets, keys);

            if (allSuccess) {
                ack.acknowledge();
                successMessages += messages.size();
                log.info("Batch acknowledged successfully");
            } else {
                failedMessages += messages.size();
                log.warn("Batch processing failed, will be retried");
            }

            log.info("=====================================");

        } catch (Exception ex) {
            failedMessages += messages.size();
            log.error("Error processing batch messages, batch size: {}", messages.size(), ex);
        }
    }

    /**
     * å¤„ç†æ‰¹é‡æ¶ˆæ¯
     */
    private boolean processBatchMessages(List<String> messages,
                                         List<Integer> partitions,
                                         List<Long> offsets,
                                         List<String> keys) {
        try {
            boolean allSuccess = true;

            for (int i = 0; i < messages.size(); i++) {
                String message = messages.get(i);
                Integer partition = partitions.get(i);
                Long offset = offsets.get(i);
                String key = keys.get(i);

                log.debug("Processing message from partition {}: key={}, value={}, offset={}",
                        partition, key, message, offset);

                boolean success = processMessage(message);
                if (!success) {
                    allSuccess = false;
                    log.warn("Message processing failed: partition={}, offset={}", partition, offset);
                }
            }

            Thread.sleep(300);
            return allSuccess;

        } catch (InterruptedException ex) {
            Thread.currentThread().interrupt();
            log.error("Batch processing interrupted", ex);
            return false;
        } catch (Exception ex) {
            log.error("Error in batch processing", ex);
            return false;
        }
    }

    /**
     * æ¶ˆæ¯å¤„ç†é€»è¾‘
     */
    private boolean processMessage(String message) {
        try {
            Thread.sleep(100);

            if (message.contains("error")) {
                log.warn("Processing error message: {}", message);
                return Math.random() > 0.3; // 70% æˆåŠŸç‡
            } else if (message.contains("urgent")) {
                log.warn("Processing urgent message: {}", message);
                return true;
            } else {
                log.debug("Processing normal message: {}", message);
                return Math.random() > 0.05; // 95% æˆåŠŸç‡
            }

        } catch (InterruptedException ex) {
            Thread.currentThread().interrupt();
            log.error("Message processing interrupted", ex);
            return false;
        } catch (Exception ex) {
            log.error("Error in message processing", ex);
            return false;
        }
    }

    /**
     * è·å–æ‰‹åŠ¨æäº¤ç»Ÿè®¡ä¿¡æ¯
     */
    public String getStatistics() {
        return String.format("Manual Commit Consumer Statistics - Total: %d, Success: %d, Failed: %d, Success Rate: %.2f%%",
                totalMessages, successMessages, failedMessages,
                totalMessages > 0 ? (double) successMessages / totalMessages * 100 : 0);
    }
}
```

## Kafka Consumeræ¶ˆè´¹æ¨¡å¼è¯¦è§£

### 1. æ¶ˆè´¹è€…ç±»å‹è¯´æ˜

æœ¬é¡¹ç›®å®ç°äº†4ç§ä¸åŒç±»å‹çš„æ¶ˆè´¹è€…ï¼š

- **ç®€å•æ¶ˆè´¹è€…ï¼ˆSimpleConsumerï¼‰**ï¼šè‡ªåŠ¨æäº¤æ¨¡å¼ï¼Œå•æ¡æ¶ˆè´¹ï¼Œæ”¯æŒ ConsumerRecord å’Œ @Payload/@Header ä¸¤ç§æ–¹å¼
- **æ‰¹é‡æ¶ˆè´¹è€…ï¼ˆBatchConsumerï¼‰**ï¼šè‡ªåŠ¨æäº¤æ¨¡å¼ï¼Œæ‰¹é‡æ¶ˆè´¹
- **æ‰‹åŠ¨æäº¤æ¶ˆè´¹è€…ï¼ˆManualCommitConsumerï¼‰**ï¼šæ‰‹åŠ¨æäº¤æ¨¡å¼ï¼Œå•æ¡æ¶ˆè´¹
- **æ‰‹åŠ¨æäº¤æ‰¹é‡æ¶ˆè´¹è€…**ï¼šæ‰‹åŠ¨æäº¤æ¨¡å¼ï¼Œæ‰¹é‡æ¶ˆè´¹

### 2. æ¶ˆè´¹æ¨¡å¼å¯¹æ¯”

| æ¶ˆè´¹æ¨¡å¼      | æäº¤æ–¹å¼ | æ¶ˆè´¹æ–¹å¼ | é€‚ç”¨åœºæ™¯      | ä¼˜ç‚¹        | ç¼ºç‚¹     |
|-----------|------|------|-----------|-----------|--------|
| ç®€å•æ¶ˆè´¹è€…     | è‡ªåŠ¨æäº¤ | å•æ¡   | ç®€å•ä¸šåŠ¡é€»è¾‘    | ç®€å•æ˜“ç”¨      | å¯èƒ½ä¸¢å¤±æ¶ˆæ¯ |
| æ‰¹é‡æ¶ˆè´¹è€…     | è‡ªåŠ¨æäº¤ | æ‰¹é‡   | é«˜ååé‡      | æ•ˆç‡é«˜       | å¯èƒ½ä¸¢å¤±æ¶ˆæ¯ |
| æ‰‹åŠ¨æäº¤æ¶ˆè´¹è€…   | æ‰‹åŠ¨æäº¤ | å•æ¡   | ç²¾ç¡®æ§åˆ¶      | æ¶ˆæ¯ä¸ä¸¢å¤±     | å¤æ‚åº¦é«˜   |
| æ‰‹åŠ¨æäº¤æ‰¹é‡æ¶ˆè´¹è€… | æ‰‹åŠ¨æäº¤ | æ‰¹é‡   | é«˜ååé‡+ç²¾ç¡®æ§åˆ¶ | æ•ˆç‡é«˜+æ¶ˆæ¯ä¸ä¸¢å¤± | å¤æ‚åº¦æœ€é«˜  |

### 3. æ¶ˆè´¹è€…é…ç½®è¯´æ˜

#### è‡ªåŠ¨æäº¤æ¨¡å¼é…ç½®

```properties
# å¯ç”¨è‡ªåŠ¨æäº¤
spring.kafka.consumer.enable-auto-commit=true
# è‡ªåŠ¨æäº¤é—´éš”
spring.kafka.consumer.auto-commit-interval=1000
# ç¡®è®¤æ¨¡å¼
spring.kafka.listener.ack-mode=batch
```

#### æ‰‹åŠ¨æäº¤æ¨¡å¼é…ç½®

```properties
# ç¦ç”¨è‡ªåŠ¨æäº¤
spring.kafka.consumer.enable-auto-commit=false
# ç¡®è®¤æ¨¡å¼
spring.kafka.listener.ack-mode=manual
```

### 4. æ¶ˆè´¹è€…ç»„è¯´æ˜

æœ¬é¡¹ç›®ä½¿ç”¨äº†ä¸åŒçš„æ¶ˆè´¹è€…ç»„IDæ¥é¿å…å†²çªï¼š

- `demo-consumer-group`ï¼šç®€å•æ¶ˆè´¹è€…
- `demo-consumer-group-payload`ï¼šç®€å•æ¶ˆè´¹è€…ï¼ˆ@Payloadæ–¹å¼ï¼‰
- `demo-consumer-group-batch`ï¼šæ‰¹é‡æ¶ˆè´¹è€…
- `demo-consumer-group-batch-payload`ï¼šæ‰¹é‡æ¶ˆè´¹è€…ï¼ˆ@Payloadæ–¹å¼ï¼‰
- `demo-consumer-group-manual`ï¼šæ‰‹åŠ¨æäº¤æ¶ˆè´¹è€…
- `demo-consumer-group-manual-payload`ï¼šæ‰‹åŠ¨æäº¤æ¶ˆè´¹è€…ï¼ˆ@Payloadæ–¹å¼ï¼‰
- `demo-consumer-group-manual-batch`ï¼šæ‰‹åŠ¨æäº¤æ‰¹é‡æ¶ˆè´¹è€…

## æµ‹è¯•æ–¹æ³•

### 1. å¯åŠ¨åº”ç”¨

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd kafka-08-Event-Consumer

# å¯åŠ¨åº”ç”¨
mvn spring-boot:run
```

### 2. å‘é€æµ‹è¯•æ¶ˆæ¯

ä½¿ç”¨Kafkaå‘½ä»¤è¡Œå·¥å…·å‘é€æ¶ˆæ¯åˆ° `demo-consumer-topic` æ¥æµ‹è¯•ä¸åŒçš„æ¶ˆè´¹è€…ï¼š

#### 2.1 ç®€å•æ¶ˆè´¹è€…æµ‹è¯•

```bash
# å‘é€å•æ¡æ¶ˆæ¯ï¼ˆæ— é”®ï¼‰
echo "Hello Kafka Consumer" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic

# å‘é€å•æ¡æ¶ˆæ¯ï¼ˆå¸¦é”®ï¼‰
echo "key1:test message with key" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"

# å‘é€Payloadæµ‹è¯•æ¶ˆæ¯
echo "Payload test message" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
echo "payload-key:Payload test with key" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"
```

#### 2.2 æ‰¹é‡æ¶ˆè´¹è€…æµ‹è¯•

```bash
# å‘é€æ‰¹é‡æ¶ˆæ¯ï¼ˆæ— é”®ï¼‰
for i in {1..5}; do echo "batch message $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; done

# å‘é€æ‰¹é‡æ¶ˆæ¯ï¼ˆå¸¦é”®ï¼‰
for i in {1..3}; do echo "batch-key-$i:batch message with key $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"; done

# å¿«é€Ÿå‘é€å¤šæ¡æ¶ˆæ¯æµ‹è¯•æ‰¹é‡æ¶ˆè´¹
for i in {1..10}; do echo "rapid message $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; sleep 0.1; done

# å‘é€Payloadæ‰¹é‡æ¶ˆæ¯
for i in {1..8}; do echo "payload batch message $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; done

# æ··åˆå‘é€æµ‹è¯•ï¼ˆéƒ¨åˆ†æœ‰é”®ï¼Œéƒ¨åˆ†æ— é”®ï¼‰
echo "mixed message 1" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
echo "mixed-key:mixed message with key" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"
echo "mixed message 3" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
```

#### 2.3 æ‰‹åŠ¨æäº¤æ¶ˆè´¹è€…æµ‹è¯•

```bash
# å‘é€å•æ¡æ¶ˆæ¯ï¼ˆæ— é”®ï¼‰
echo "Manual commit test message" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic

# å‘é€å•æ¡æ¶ˆæ¯ï¼ˆå¸¦é”®ï¼‰
echo "manual-key:Manual commit with key" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"

# å‘é€é”™è¯¯æ¶ˆæ¯æµ‹è¯•é‡è¯•æœºåˆ¶
echo "error message for retry test" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic

# å‘é€ç´§æ€¥æ¶ˆæ¯æµ‹è¯•
echo "urgent message for priority test" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic

# å‘é€Payloadæ‰‹åŠ¨æäº¤æµ‹è¯•
echo "Manual payload test message" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
echo "manual-payload-key:Manual payload with key" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"

# å‘é€æ‰¹é‡æ‰‹åŠ¨æäº¤æµ‹è¯•
for i in {1..6}; do echo "manual batch message $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; done

# å¿«é€Ÿå‘é€å¤šæ¡æ¶ˆæ¯æµ‹è¯•æ‰¹é‡æ‰‹åŠ¨æäº¤
for i in {1..15}; do echo "rapid manual batch $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; sleep 0.05; done

# å‘é€åŒ…å«é”™è¯¯æ¶ˆæ¯çš„æ‰¹æ¬¡æµ‹è¯•
echo "normal message 1" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
echo "error message for batch retry" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
echo "normal message 3" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
```

#### 2.4 é€šç”¨æµ‹è¯•å‘½ä»¤

```bash
# å‘é€å•æ¡æ¶ˆæ¯ï¼ˆäº¤äº’å¼ï¼‰
kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic

# å‘é€å¸¦é”®çš„æ¶ˆæ¯ï¼ˆäº¤äº’å¼ï¼‰
kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"

# å‘é€å¤§é‡æ¶ˆæ¯è¿›è¡Œå‹åŠ›æµ‹è¯•
for i in {1..100}; do echo "stress test message $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; done
```

### 3. è§‚å¯Ÿæ—¥å¿—è¾“å‡º

å¯åŠ¨åº”ç”¨åï¼Œè§‚å¯Ÿæ§åˆ¶å°æ—¥å¿—ï¼š

#### ç®€å•æ¶ˆè´¹è€…æ—¥å¿—

```
INFO  - === Simple Consumer (ConsumerRecord) ===
INFO  - Topic: demo-consumer-topic
INFO  - Partition: 0
INFO  - Offset: 123
INFO  - Key: null
INFO  - Value: test message
INFO  - Timestamp: 1640995200000
INFO  - Headers: []
INFO  - ================================
```

#### æ‰¹é‡æ¶ˆè´¹è€…æ—¥å¿—

```
INFO  - === Batch Consumer (List<ConsumerRecord>) ===
INFO  - Batch size: 5
INFO  - Total batches processed: 1
INFO  - Total messages processed: 5
INFO  - ==========================================
```

#### æ‰‹åŠ¨æäº¤æ¶ˆè´¹è€…æ—¥å¿—

```
INFO  - === Manual Commit Consumer (ConsumerRecord) ===
INFO  - Topic: demo-consumer-topic
INFO  - Partition: 0
INFO  - Offset: 124
INFO  - Key: null
INFO  - Value: test message
INFO  - Total messages: 1, Success: 1, Failed: 0
INFO  - Message acknowledged successfully
INFO  - =============================================
```

## æµ‹è¯•å‘½ä»¤å¿«é€Ÿå‚è€ƒ

### æ¶ˆè´¹è€…ç±»å‹ä¸æµ‹è¯•å‘½ä»¤å¯¹åº”å…³ç³»

| æ¶ˆè´¹è€…ç±»å‹                                 | æ¶ˆè´¹è€…ç»„ID                             | æµ‹è¯•å‘½ä»¤ç¤ºä¾‹                                                                                                                                                                                         |
|---------------------------------------|------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| SimpleConsumer (ConsumerRecord)       | demo-consumer-group                | `echo "Hello Kafka" \| kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic`                                                                                |
| SimpleConsumer (@Payload)             | demo-consumer-group-payload        | `echo "payload-key:Payload test" \| kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"`          |
| BatchConsumer (ConsumerRecord)        | demo-consumer-group-batch          | `for i in {1..5}; do echo "batch $i" \| kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; done`                                                         |
| BatchConsumer (@Payload)              | demo-consumer-group-batch-payload  | `for i in {1..8}; do echo "payload batch $i" \| kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; done`                                                 |
| ManualCommitConsumer (ConsumerRecord) | demo-consumer-group-manual         | `echo "Manual commit test" \| kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic`                                                                         |
| ManualCommitConsumer (@Payload)       | demo-consumer-group-manual-payload | `echo "manual-payload-key:Manual payload" \| kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"` |
| ManualCommitConsumer (Batch)          | demo-consumer-group-manual-batch   | `for i in {1..6}; do echo "manual batch $i" \| kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; done`                                                  |

### ç‰¹æ®Šæµ‹è¯•åœºæ™¯

| æµ‹è¯•åœºæ™¯   | å‘½ä»¤                                                                                                                                                                                                                                                                                                                            | è¯´æ˜             |
|--------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------|
| é”™è¯¯æ¶ˆæ¯é‡è¯• | `echo "error message for retry test" \| kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic`                                                                                                                                                                                              | æµ‹è¯•æ‰‹åŠ¨æäº¤æ¶ˆè´¹è€…çš„é‡è¯•æœºåˆ¶ |
| ç´§æ€¥æ¶ˆæ¯å¤„ç† | `echo "urgent message for priority test" \| kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic`                                                                                                                                                                                          | æµ‹è¯•ç´§æ€¥æ¶ˆæ¯çš„ä¼˜å…ˆå¤„ç†    |
| æ‰¹é‡é”™è¯¯æµ‹è¯• | `echo "normal" \| kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; echo "error" \| kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; echo "normal" \| kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic` | æµ‹è¯•æ‰¹é‡æ¶ˆè´¹ä¸­çš„é”™è¯¯å¤„ç†   |
| å‹åŠ›æµ‹è¯•   | `for i in {1..100}; do echo "stress test $i" \| kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; done`                                                                                                                                                                                | æµ‹è¯•å¤§é‡æ¶ˆæ¯çš„å¤„ç†èƒ½åŠ›    |

## æ³¨æ„äº‹é¡¹

1. **KafkaæœåŠ¡å™¨**: ç¡®ä¿KafkaæœåŠ¡å™¨åœ¨`localhost:9092`è¿è¡Œ
2. **æ¶ˆè´¹è€…ç»„**: ä¸åŒæ¶ˆè´¹è€…ä½¿ç”¨ä¸åŒçš„æ¶ˆè´¹è€…ç»„IDï¼Œé¿å…å†²çª
3. **åç§»é‡ç®¡ç†**: æ‰‹åŠ¨æäº¤æ¨¡å¼ä¸‹éœ€è¦æ­£ç¡®å¤„ç†å¼‚å¸¸æƒ…å†µ
4. **æ‰¹é‡æ¶ˆè´¹**: æ‰¹é‡æ¶ˆè´¹æ—¶å¼‚å¸¸ä¼šä¸­æ–­æ•´ä¸ªæ‰¹æ¬¡
5. **æ€§èƒ½è°ƒä¼˜**: æ ¹æ®ä¸šåŠ¡éœ€æ±‚è°ƒæ•´æ‰¹é‡å¤§å°å’Œå¹¶å‘æ•°
6. **ç›‘æ§å‘Šè­¦**: åˆ©ç”¨ç»Ÿè®¡ä¿¡æ¯å®ç°æ¶ˆè´¹è€…ç›‘æ§å’Œå‘Šè­¦
7. **é”™è¯¯å¤„ç†**: å®ç°å®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œé‡è¯•æœºåˆ¶
8. **èµ„æºç®¡ç†**: åˆç†é…ç½®æ¶ˆè´¹è€…å‚æ•°ï¼Œé¿å…èµ„æºæµªè´¹
9. **æµ‹è¯•å‘½ä»¤**: æ¯ä¸ªæ¶ˆè´¹è€…æ–¹æ³•éƒ½åŒ…å«è¯¦ç»†çš„æµ‹è¯•å‘½ä»¤æ³¨é‡Šï¼Œå¯ç›´æ¥å¤åˆ¶ä½¿ç”¨
10. **é”®å€¼åˆ†ç¦»**: ä½¿ç”¨`--property "parse.key=true" --property "key.separator=:"`æ¥å‘é€å¸¦é”®çš„æ¶ˆæ¯
