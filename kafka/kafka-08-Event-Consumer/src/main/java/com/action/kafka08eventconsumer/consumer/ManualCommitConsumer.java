package com.action.kafka08eventconsumer.consumer;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.kafka.support.KafkaHeaders;
import org.springframework.messaging.handler.annotation.Header;
import org.springframework.messaging.handler.annotation.Payload;
import org.springframework.stereotype.Component;

import java.util.List;

/**
 * æ‰‹åŠ¨æäº¤æ¶ˆè´¹è€… - æ¼”ç¤ºæ‰‹åŠ¨æäº¤åç§»é‡çš„æ¶ˆæ¯æ¶ˆè´¹åŠŸèƒ½
 * 
 * åŠŸèƒ½è¯´æ˜ï¼š
 * 1) æ‰‹åŠ¨æäº¤æ¨¡å¼ï¼šæ¶ˆè´¹æ¶ˆæ¯åéœ€è¦æ‰‹åŠ¨ç¡®è®¤åç§»é‡
 * 2) ç²¾ç¡®æ§åˆ¶ï¼šå¯ä»¥æ§åˆ¶ä½•æ—¶æäº¤åç§»é‡ï¼Œé¿å…æ¶ˆæ¯ä¸¢å¤±
 * 3) å¼‚å¸¸å¤„ç†ï¼šæ”¯æŒæ¶ˆè´¹å¤±è´¥æ—¶çš„é‡è¯•å’Œå›æ»šæœºåˆ¶
 * 4) æ‰¹é‡ç¡®è®¤ï¼šæ”¯æŒæ‰¹é‡å¤„ç†åçš„æ‰¹é‡ç¡®è®¤
 * 
 * å®ç°ç»†èŠ‚ï¼š
 * - ä½¿ç”¨ @KafkaListener æ³¨è§£æ ‡è®°æ¶ˆè´¹æ–¹æ³•
 * - ä½¿ç”¨ manualCommitKafkaListenerContainerFactory å®¹å™¨å·¥å‚
 * - å¿…é¡»è°ƒç”¨ Acknowledgment.acknowledge() ç¡®è®¤æ¶ˆæ¯
 * - å¼‚å¸¸æ—¶å¯ä»¥é€‰æ‹©æ˜¯å¦ç¡®è®¤æ¶ˆæ¯
 * 
 * å…³é”®å‚æ•°è¯´æ˜ï¼š
 * - Acknowledgment: æ‰‹åŠ¨ç¡®è®¤æ¥å£ï¼Œå¿…é¡»è°ƒç”¨ acknowledge() æ–¹æ³•
 * - ConsumerRecord: åŒ…å«å®Œæ•´çš„æ¶ˆæ¯ä¿¡æ¯
 * - @Payload: ç›´æ¥è·å–æ¶ˆæ¯å€¼
 * - @Header: è·å–æ¶ˆæ¯å¤´ä¿¡æ¯
 */
@Component
public class ManualCommitConsumer {

    private static final Logger log = LoggerFactory.getLogger(ManualCommitConsumer.class);

    /**
     * æ¶ˆè´¹è€…ç»„IDé…ç½®
     */
    @Value("${spring.kafka.consumer.group-id:demo-consumer-group}")
    private String groupId;

    /**
     * Topicåç§°é…ç½®
     */
    @Value("${demo.topic.name:demo-consumer-topic}")
    private String topicName;

    // æ‰‹åŠ¨æäº¤ç»Ÿè®¡ä¿¡æ¯
    private long totalMessages = 0;
    private long successMessages = 0;
    private long failedMessages = 0;

    /**
     * æ‰‹åŠ¨æäº¤æ¶ˆæ¯æ¶ˆè´¹æ–¹æ³•ï¼ˆä½¿ç”¨ ConsumerRecordï¼‰
     * 
     * æ‰§è¡Œæ—¶æœºï¼šå½“æœ‰æ¶ˆæ¯åˆ°è¾¾æŒ‡å®š topic æ—¶
     * ä½œç”¨ï¼šå¤„ç†å•æ¡æ¶ˆæ¯ï¼Œæ‰‹åŠ¨ç¡®è®¤åç§»é‡
     * 
     * å‚æ•°è¯´æ˜ï¼š
     * - topics: ç›‘å¬çš„ topic åç§°
     * - groupId: æ¶ˆè´¹è€…ç»„ID
     * - containerFactory: ä½¿ç”¨æ‰‹åŠ¨æäº¤çš„ç›‘å¬å™¨å®¹å™¨å·¥å‚
     * 
     * æµ‹è¯•å‘½ä»¤ï¼š
     * # å‘é€å•æ¡æ¶ˆæ¯ï¼ˆæ— é”®ï¼‰
     * kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     * 
     * # å‘é€å•æ¡æ¶ˆæ¯ï¼ˆå¸¦é”®ï¼‰
     * kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"
     * 
     * # å‘é€æµ‹è¯•æ¶ˆæ¯ç¤ºä¾‹
     * echo "Manual commit test message" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     * echo "manual-key:Manual commit with key" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"
     * 
     * # å‘é€é”™è¯¯æ¶ˆæ¯æµ‹è¯•é‡è¯•æœºåˆ¶
     * echo "error message for retry test" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     * 
     * @param record å®Œæ•´çš„æ¶ˆæ¯è®°å½•
     * @param ack æ‰‹åŠ¨ç¡®è®¤æ¥å£
     */
    @KafkaListener(
        topics = "${demo.topic.name:demo-consumer-topic}",
        groupId = "${spring.kafka.consumer.group-id:demo-consumer-group}-manual",
        containerFactory = "manualCommitKafkaListenerContainerFactory"
    )
    public void consumeMessageWithManualCommit(ConsumerRecord<String, String> record, Acknowledgment ack) {
        try {
            totalMessages++;
            
            // æ‰‹åŠ¨æäº¤æ¶ˆè´¹ä¿¡æ¯æ—¥å¿—
            log.info("ğŸ“¦ Manual Commit Consumer (ConsumerRecord) ğŸ‘¥ Group: {} ğŸ“‹ Topic: {} ğŸ”¢ Partition: {} ğŸ“ Offset: {} ğŸ”‘ Key: {} ğŸ’¬ Value: {} â° Timestamp: {} ğŸ“Š Total: {} Success: {} Failed: {}", 
                    groupId + "-manual", record.topic(), record.partition(), record.offset(), record.key(), record.value(), record.timestamp(), totalMessages, successMessages, failedMessages);
            
            // å¤„ç†æ¶ˆæ¯
            boolean success = processMessage(record.value());
            
            if (success) {
                // å¤„ç†æˆåŠŸï¼šç¡®è®¤æ¶ˆæ¯
                ack.acknowledge();
                successMessages++;
                log.info("âœ… Message acknowledged successfully");
            } else {
                // å¤„ç†å¤±è´¥ï¼šä¸ç¡®è®¤æ¶ˆæ¯ï¼Œä¼šé‡æ–°æ¶ˆè´¹
                failedMessages++;
                log.warn("âŒ Message processing failed, will be retried");
            }
            
        } catch (Exception ex) {
            // å¼‚å¸¸å¤„ç†ï¼šè®°å½•é”™è¯¯æ—¥å¿—ï¼Œä¸ç¡®è®¤æ¶ˆæ¯
            failedMessages++;
            log.error("Error processing message from topic={}, partition={}, offset={}", 
                     record.topic(), record.partition(), record.offset(), ex);
            
            // æ³¨æ„ï¼šå¼‚å¸¸æ—¶ä¸è°ƒç”¨ ack.acknowledge()ï¼Œæ¶ˆæ¯ä¼šè¢«é‡æ–°æ¶ˆè´¹
        }
    }

    /**
     * æ‰‹åŠ¨æäº¤æ¶ˆæ¯æ¶ˆè´¹æ–¹æ³•ï¼ˆä½¿ç”¨ @Payload å’Œ @Headerï¼‰
     * 
     * æ‰§è¡Œæ—¶æœºï¼šå½“æœ‰æ¶ˆæ¯åˆ°è¾¾æŒ‡å®š topic æ—¶
     * ä½œç”¨ï¼šä½¿ç”¨æ³¨è§£æ–¹å¼ç®€åŒ–å‚æ•°å¤„ç†ï¼Œæ‰‹åŠ¨ç¡®è®¤åç§»é‡
     * 
     * å‚æ•°è¯´æ˜ï¼š
     * - @Payload: ç›´æ¥è·å–æ¶ˆæ¯å€¼
     * - @Header: è·å–æ¶ˆæ¯å¤´ä¿¡æ¯
     * - Acknowledgment: æ‰‹åŠ¨ç¡®è®¤æ¥å£
     * 
     * æµ‹è¯•å‘½ä»¤ï¼š
     * # å‘é€å•æ¡æ¶ˆæ¯ï¼ˆæ— é”®ï¼‰
     * kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     * 
     * # å‘é€å•æ¡æ¶ˆæ¯ï¼ˆå¸¦é”®ï¼‰
     * kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"
     * 
     * # å‘é€æµ‹è¯•æ¶ˆæ¯ç¤ºä¾‹
     * echo "Manual payload test message" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     * echo "manual-payload-key:Manual payload with key" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"
     * 
     * # å‘é€ç´§æ€¥æ¶ˆæ¯æµ‹è¯•
     * echo "urgent message for priority test" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     * 
     * @param message æ¶ˆæ¯å€¼
     * @param partition åˆ†åŒºå·
     * @param offset åç§»é‡
     * @param key æ¶ˆæ¯é”®
     * @param ack æ‰‹åŠ¨ç¡®è®¤æ¥å£
     */
    @KafkaListener(
        topics = "${demo.topic.name:demo-consumer-topic}",
        groupId = "${spring.kafka.consumer.group-id:demo-consumer-group}-manual-payload",
        containerFactory = "manualCommitKafkaListenerContainerFactory"
    )
    public void consumeMessageWithManualCommitPayload(
            @Payload String message,
            @Header(KafkaHeaders.RECEIVED_PARTITION) int partition,
            @Header(KafkaHeaders.OFFSET) long offset,
            @Header(value = KafkaHeaders.RECEIVED_KEY, required = false) String key,
            Acknowledgment ack) {
        
        try {
            totalMessages++;
            
            // æ‰‹åŠ¨æäº¤æ¶ˆè´¹ä¿¡æ¯æ—¥å¿—
            log.info("ğŸ“¦ Manual Commit Consumer (@Payload/@Header) ğŸ‘¥ Group: {} ğŸ”¢ Partition: {} ğŸ“ Offset: {} ğŸ”‘ Key: {} ğŸ’¬ Value: {} ğŸ“Š Total: {} Success: {} Failed: {}", 
                    groupId + "-manual-payload", partition, offset, key != null ? key : "null", message, totalMessages, successMessages, failedMessages);
            
            // å¤„ç†æ¶ˆæ¯
            boolean success = processMessage(message);
            
            if (success) {
                // å¤„ç†æˆåŠŸï¼šç¡®è®¤æ¶ˆæ¯
                ack.acknowledge();
                successMessages++;
                log.info("âœ… Message acknowledged successfully");
            } else {
                // å¤„ç†å¤±è´¥ï¼šä¸ç¡®è®¤æ¶ˆæ¯ï¼Œä¼šé‡æ–°æ¶ˆè´¹
                failedMessages++;
                log.warn("âŒ Message processing failed, will be retried");
            }
            
        } catch (Exception ex) {
            // å¼‚å¸¸å¤„ç†ï¼šè®°å½•é”™è¯¯æ—¥å¿—ï¼Œä¸ç¡®è®¤æ¶ˆæ¯
            failedMessages++;
            log.error("Error processing message from partition={}, offset={}", 
                     partition, offset, ex);
            
            // æ³¨æ„ï¼šå¼‚å¸¸æ—¶ä¸è°ƒç”¨ ack.acknowledge()ï¼Œæ¶ˆæ¯ä¼šè¢«é‡æ–°æ¶ˆè´¹
        }
    }

    /**
     * æ‰‹åŠ¨æäº¤æ‰¹é‡æ¶ˆæ¯æ¶ˆè´¹æ–¹æ³•
     * 
     * æ‰§è¡Œæ—¶æœºï¼šå½“æœ‰æ¶ˆæ¯æ‰¹æ¬¡åˆ°è¾¾æŒ‡å®š topic æ—¶
     * ä½œç”¨ï¼šæ‰¹é‡å¤„ç†æ¶ˆæ¯ï¼Œæ‰¹é‡ç¡®è®¤åç§»é‡
     * 
     * å‚æ•°è¯´æ˜ï¼š
     * - @Payload: æ‰¹é‡æ¶ˆæ¯å€¼åˆ—è¡¨
     * - @Header: æ‰¹é‡æ¶ˆæ¯çš„å…¬å…±å¤´ä¿¡æ¯
     * - Acknowledgment: æ‰‹åŠ¨ç¡®è®¤æ¥å£
     * 
     * æµ‹è¯•å‘½ä»¤ï¼š
     * # å‘é€æ‰¹é‡æ¶ˆæ¯ï¼ˆæ— é”®ï¼‰
     * for i in {1..6}; do echo "manual batch message $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; done
     * 
     * # å‘é€æ‰¹é‡æ¶ˆæ¯ï¼ˆå¸¦é”®ï¼‰
     * for i in {1..4}; do echo "manual-batch-key-$i:manual batch with key $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic --property "parse.key=true" --property "key.separator=:"; done
     * 
     * # å¿«é€Ÿå‘é€å¤šæ¡æ¶ˆæ¯æµ‹è¯•æ‰¹é‡æ‰‹åŠ¨æäº¤
     * for i in {1..15}; do echo "rapid manual batch $i" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic; sleep 0.05; done
     * 
     * # å‘é€åŒ…å«é”™è¯¯æ¶ˆæ¯çš„æ‰¹æ¬¡æµ‹è¯•
     * echo "normal message 1" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     * echo "error message for batch retry" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     * echo "normal message 3" | kafka-console-producer.sh --bootstrap-server localhost:9092 --topic demo-consumer-topic
     * 
     * @param messages æ‰¹é‡æ¶ˆæ¯å€¼åˆ—è¡¨
     * @param partitions åˆ†åŒºå·åˆ—è¡¨
     * @param offsets åç§»é‡åˆ—è¡¨
     * @param keys æ¶ˆæ¯é”®åˆ—è¡¨
     * @param ack æ‰‹åŠ¨ç¡®è®¤æ¥å£
     */
    @KafkaListener(
        topics = "${demo.topic.name:demo-consumer-topic}",
        groupId = "${spring.kafka.consumer.group-id:demo-consumer-group}-manual-batch",
        containerFactory = "manualCommitKafkaListenerContainerFactory"
    )
    public void consumeBatchMessagesWithManualCommit(
            @Payload List<String> messages,
            @Header(KafkaHeaders.RECEIVED_PARTITION) List<Integer> partitions,
            @Header(KafkaHeaders.OFFSET) List<Long> offsets,
            @Header(value = KafkaHeaders.RECEIVED_KEY, required = false) List<String> keys,
            Acknowledgment ack) {
        
        try {
            totalMessages += messages.size();
            
            // æ‰¹é‡æ‰‹åŠ¨æäº¤æ¶ˆè´¹ä¿¡æ¯æ—¥å¿—
            log.info("ğŸ“¦ Manual Commit Batch Consumer ğŸ‘¥ Group: {} ğŸ“Š Batch size: {} ğŸ”¢ Partitions: {} ğŸ“ Offsets: {} ğŸ”‘ Keys: {} ğŸ“Š Total: {} Success: {} Failed: {}", 
                    groupId + "-manual-batch", messages.size(), partitions, offsets, keys != null ? keys : "null", totalMessages, successMessages, failedMessages);
            
            // å¤„ç†æ‰¹é‡æ¶ˆæ¯
            boolean allSuccess = processBatchMessages(messages, partitions, offsets, keys);
            
            if (allSuccess) {
                // å…¨éƒ¨å¤„ç†æˆåŠŸï¼šç¡®è®¤æ•´ä¸ªæ‰¹æ¬¡
                ack.acknowledge();
                successMessages += messages.size();
                log.info("âœ… Batch acknowledged successfully");
            } else {
                // éƒ¨åˆ†å¤„ç†å¤±è´¥ï¼šä¸ç¡®è®¤æ‰¹æ¬¡ï¼Œä¼šé‡æ–°æ¶ˆè´¹
                failedMessages += messages.size();
                log.warn("âŒ Batch processing failed, will be retried");
            }
            
        } catch (Exception ex) {
            // å¼‚å¸¸å¤„ç†ï¼šè®°å½•é”™è¯¯æ—¥å¿—ï¼Œä¸ç¡®è®¤æ‰¹æ¬¡
            failedMessages += messages.size();
            log.error("Error processing batch messages, batch size: {}", messages.size(), ex);
            
            // æ³¨æ„ï¼šå¼‚å¸¸æ—¶ä¸è°ƒç”¨ ack.acknowledge()ï¼Œæ•´ä¸ªæ‰¹æ¬¡ä¼šè¢«é‡æ–°æ¶ˆè´¹
        }
    }

    /**
     * å¤„ç†æ‰¹é‡æ¶ˆæ¯
     * 
     * ä½œç”¨ï¼šå¤„ç†æ‰¹é‡æ¶ˆæ¯ï¼Œè¿”å›æ˜¯å¦å…¨éƒ¨æˆåŠŸ
     * å®ç°ï¼šéå†æ¶ˆæ¯åˆ—è¡¨ï¼Œè¿›è¡Œæ‰¹é‡å¤„ç†
     * 
     * @param messages æ¶ˆæ¯å€¼åˆ—è¡¨
     * @param partitions åˆ†åŒºå·åˆ—è¡¨
     * @param offsets åç§»é‡åˆ—è¡¨
     * @param keys æ¶ˆæ¯é”®åˆ—è¡¨
     * @return æ˜¯å¦å…¨éƒ¨å¤„ç†æˆåŠŸ
     */
    private boolean processBatchMessages(List<String> messages, 
                                       List<Integer> partitions, 
                                       List<Long> offsets, 
                                       List<String> keys) {
        try {
            boolean allSuccess = true;
            
            // å¤„ç†æ¯æ¡æ¶ˆæ¯
            for (int i = 0; i < messages.size(); i++) {
                String message = messages.get(i);
                Integer partition = partitions.get(i);
                Long offset = offsets.get(i);
                String key = keys != null ? keys.get(i) : null;
                
                log.debug("Processing message from partition {}: key={}, value={}, offset={}", 
                         partition, key != null ? key : "null", message, offset);
                
                boolean success = processMessage(message);
                if (!success) {
                    allSuccess = false;
                    log.warn("Message processing failed: partition={}, offset={}", partition, offset);
                }
            }
            
            // æ¨¡æ‹Ÿæ‰¹é‡å¤„ç†æ—¶é—´
            Thread.sleep(300);
            
            return allSuccess;
            
        } catch (InterruptedException ex) {
            Thread.currentThread().interrupt();
            log.error("Batch processing interrupted", ex);
            return false;
        } catch (Exception ex) {
            log.error("Error in batch processing", ex);
            return false;
        }
    }

    /**
     * æ¶ˆæ¯å¤„ç†é€»è¾‘
     * 
     * ä½œç”¨ï¼šæ¨¡æ‹Ÿå®é™…çš„æ¶ˆæ¯å¤„ç†ä¸šåŠ¡é€»è¾‘
     * å®ç°ï¼šå¯ä»¥æ ¹æ®æ¶ˆæ¯å†…å®¹è¿›è¡Œä¸åŒçš„å¤„ç†ï¼Œè¿”å›å¤„ç†ç»“æœ
     * 
     * @param message æ¶ˆæ¯å†…å®¹
     * @return å¤„ç†æ˜¯å¦æˆåŠŸ
     */
    private boolean processMessage(String message) {
        try {
            // æ¨¡æ‹Ÿä¸šåŠ¡å¤„ç†æ—¶é—´
            Thread.sleep(100);
            
            // æ ¹æ®æ¶ˆæ¯å†…å®¹è¿›è¡Œä¸åŒå¤„ç†
            if (message.contains("error")) {
                log.warn("Processing error message: {}", message);
                // æ¨¡æ‹Ÿé”™è¯¯æ¶ˆæ¯å¤„ç†å¤±è´¥
                return Math.random() > 0.3; // 70% æˆåŠŸç‡
            } else if (message.contains("urgent")) {
                log.warn("Processing urgent message: {}", message);
                // ç´§æ€¥æ¶ˆæ¯æ€»æ˜¯æˆåŠŸ
                return true;
            } else {
                log.debug("Processing normal message: {}", message);
                // æ™®é€šæ¶ˆæ¯ 95% æˆåŠŸç‡
                return Math.random() > 0.05;
            }
            
        } catch (InterruptedException ex) {
            Thread.currentThread().interrupt();
            log.error("Message processing interrupted", ex);
            return false;
        } catch (Exception ex) {
            log.error("Error in message processing", ex);
            return false;
        }
    }

    /**
     * è·å–æ‰‹åŠ¨æäº¤ç»Ÿè®¡ä¿¡æ¯
     * 
     * @return ç»Ÿè®¡ä¿¡æ¯å­—ç¬¦ä¸²
     */
    public String getStatistics() {
        return String.format("Manual Commit Consumer Statistics - Total: %d, Success: %d, Failed: %d, Success Rate: %.2f%%", 
                           totalMessages, successMessages, failedMessages, 
                           totalMessages > 0 ? (double) successMessages / totalMessages * 100 : 0);
    }
}
